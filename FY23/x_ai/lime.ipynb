{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI coding sessionspring 2023, investigating LIME\n",
    "\n",
    "In this notebook you are going to investigate how the LIME package can be used to investigate explainability of an Extra Tree Regressor. \n",
    "\n",
    "An Extra Tree Regressor works like the random forests algorithm. \n",
    "\n",
    "It creates many decision trees, but the sampling for each tree is random, without replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avoje001/Documents/DS_team/ds_venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset using sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/h\n"
     ]
    }
   ],
   "source": [
    "# Displaying relevant information about the data\n",
    "print(data['DESCR'][200:1420])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature matrix X and target variable y, and do a train-test split\n",
    "\n",
    "Go through the code in the cell below and ensure you understand what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data = (506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  label  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating data into feature variable X and target variable y respectively\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data['data']\n",
    "y = data['target']\n",
    " \n",
    "# Extracting the names of the features from data\n",
    "features = data['feature_names']\n",
    " \n",
    "# Splitting X & y into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.90, random_state=50)\n",
    " \n",
    "# Creating a dataframe of the data, for a visual check\n",
    "df = pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1)\n",
    "df.columns = np.concatenate((features, np.array(['label'])))\n",
    "print(\"Shape of data =\", df.shape)\n",
    " \n",
    "# Printing the top 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the prediction model and train it on (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the prediction model - an extra-trees regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor(random_state=50)\n",
    " \n",
    "# Fit/train the prediction model onto the training set\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Check the model's global performance on the test set\n",
    "R2 = model.score(X_test, y_test)\n",
    "print('R2 score for the model on test set =', R2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to refresh your R2 knowledge, here's a good link:\n",
    "https://www.geeksforgeeks.org/ml-r-squared-in-regression-analysis/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the global permutational variable importance:\n",
    "\n",
    "We will now investigate a simplified version of the global permutational variable importance. \n",
    "The reason is to understand how LIME performs similar tasks, but locally.\n",
    "\n",
    "**Task:** read the pseudocode and write your own function for permutational variable importance based on it.\n",
    "\n",
    "**Pseudocode:** \n",
    "\n",
    "Loop over the features in the training set and for each iteration:\n",
    "1. Randomly permute the feature in question of the X_test set\n",
    "2. For each iteration calculate the error metric on the test set, and store it. Use the R2 score in this case too. \n",
    "\n",
    "After the loop:\n",
    "\n",
    "Store R2 from permutations in a dataframe together with the model's feature names.\n",
    "\n",
    "Sort the dataframe on the R2 score. \n",
    "\n",
    "How should the sorting be? High to low, or low to high?\n",
    "\n",
    "Interpret the results. What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Permuational Variable Importance\n",
    "\n",
    "#Allocate a list for storing the permuational performance:\n",
    "R2_perm = \n",
    "\n",
    "#Loop over all features in the training set:\n",
    "for i in range(X_test.shape[1]):\n",
    "    # Initialize the permutational test set\n",
    "    X_test_perm = X_test\n",
    "    # randomly shuffle the variable of iteration i\n",
    "    np.random.shuffle()\n",
    "    # Calculate the model's R2 score on the permuted X_test and unchanged y_test\n",
    "    # store the R2 score in the R2_perm list\n",
    "    R2_perm[i] = model.score(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature   R2_perm\n",
      "12    LSTAT -0.552522\n",
      "11        B -0.268429\n",
      "10  PTRATIO -0.251312\n",
      "4       NOX -0.236540\n",
      "2     INDUS -0.221942\n",
      "3      CHAS -0.216179\n",
      "1        ZN -0.204543\n",
      "0      CRIM -0.200624\n",
      "9       TAX -0.173019\n",
      "5        RM -0.170617\n",
      "6       AGE -0.167722\n",
      "8       RAD -0.128328\n",
      "7       DIS -0.123202\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas dataframe  by concatenating the R2_perm list with the features list\n",
    "# Sort the dataframe on the R2_perm column\n",
    "# Interpret the results\n",
    "\n",
    "global_varimp = \n",
    "\n",
    "#Sort the dataframe by the R2 column. Should the values be from low to high, or from high to low?\n",
    "global_varimp = global_varimp.sort_values(by=, ascending=)\n",
    "print(global_varimp)\n",
    "\n",
    "### interpret the results ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the permutational code several times. What do you see regarding the order of features and the R2-values? \n",
    "\n",
    "Discuss what could be done in order to find the final global permutational variable importance?\n",
    "\n",
    "Built-in permuation importance method in scikit-learn: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the solution notebook (not in this one) you will be provided with an example of permutational importance coded with an extra loop over K permuational iterations of each feature, as in the link to scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How LIME works\n",
    "\n",
    "Shortly explained: Basically, LIME generates artificial data using our input data, trains a simple ML model (on artificial data) that has the same performance as our complex black-box model, and uses this model's weights to describe the feature importance. \n",
    "\n",
    "More detailed:\n",
    "\n",
    "1. LIME takes an individual sample and generates an artificial dataset (subset around the sample in question) based on it. It then permutes the artificial dataset.\n",
    "\n",
    "2. Then LIME calculates distance metrics (or similarity metrics) between permuted artificial data and original observations. This helps to understand how similar permuted artificial data is compared to original data. \n",
    "The LIME library methods provide us with options to try different similarity metrics for this purpose.\n",
    "\n",
    "3. Then LIME makes a prediction on this new permuted artificial data using the original complex model.\n",
    "\n",
    "4. It then picks features that best describe the complex model's performance on permuted artificial data. The LIME library lets us pick how many features to evaluate.\n",
    "\n",
    "5. It then fits a simple model (like linear or logistic regression) on the combination of permuted artificial data with selected number of features and similarity scores computed in earlier steps. The LIME library takes an imput on which simple model we want to use. Generally, it's linear regression or logistic regression but it is possible to change it.\n",
    "\n",
    "6. Finally, LIME uses weights derived from the simple model for each feature to explain how each feature contributed to the prediction for that local sample when predicted by the original complex model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME - Instantiating the explainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for LimeTabularExplainer\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Instantiate the explainer object by passing in the training set, and the extracted features\n",
    "explainer_lime = lime.lime_tabular.LimeTabularExplainer(training_data= ,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature_names= ,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tverbose=True, mode='regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting explanations by calling the explain_instance() method\n",
    "\n",
    "Suppose we want to explore the main model’s reasoning behind the prediction it gave for the i’th test vector.\n",
    "\n",
    "Moreover, say we want to visualize the top k features which led to this reasoning.\n",
    "\n",
    "## Explaining the decisions for sample i=10, k=5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index corresponding to the test vector\n",
    "i = 10\n",
    "\n",
    "# Number denoting the top features\n",
    "k = 5\n",
    "\n",
    "# Call the explain_instance method by passing in the:\n",
    "# ith test vector,\n",
    "# the prediction function used by our prediction model\n",
    "# the k top features which we want to see\n",
    "exp_lime_1 = explainer_lime.explain_instance(data_row = , predict_fn = , num_features = )\n",
    "\n",
    "# Finally visualizing the explanations\n",
    "exp_lime_1.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the results. What do they mean? Does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local R2-score explanation 1:\n",
    "\n",
    "Investigate the local R2-score by using .score on the explanation exp_lime_1. How do you interpret this number? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_lime_1.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate another example:\n",
    "\n",
    "Explain the decisions made by the model for for i=47, and top 5 features (k=5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index corresponding to the test vector\n",
    "i = 47\n",
    "\n",
    "# Number denoting the top features\n",
    "k = 5\n",
    "\n",
    "# Calling the explain_instance method by passing in the:\n",
    "# ith test vector\n",
    "# prediction function used by our prediction model\n",
    "# the top features which we want to see, denoted by k\n",
    "exp_lime_2 = explainer_lime.explain_instance(data_row = , predict_fn = , num_features= )\n",
    "\n",
    "# Finally visualizing the explanations\n",
    "exp_lime_2.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the results. What do they mean? Does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local R2 score explanation 2:\n",
    "Investigate the local R2-score of explanation exp_lime_2. \n",
    "Use the same approach as for explanation 1. \n",
    "How do you interpret this number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_lime_2.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which explanation is more reliable of the two you have investigated?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('ds_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f09d290358f4b543f3df56dc3da717a422dd2a8640442be7fa8c28966dc7b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
