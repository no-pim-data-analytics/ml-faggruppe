{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Processing With Python \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction\n",
    "- [Read CSV Data](#read-CSV-data) \n",
    "    - Import `pandas`\n",
    "    - Read CSV data with `pandas`\n",
    "    - Inspect a `pandas` data frame\n",
    "    - Add parameters to read data properly\n",
    "    - Rename columns/variables\n",
    "    - Exercise\n",
    "- [Tidy Data](#tidy-data) @Aurora\n",
    "    - Obervations and variables\n",
    "    - Melt messy data to create tidy data\n",
    "    - Visualizations\n",
    "    - Exercise\n",
    "- [Process Data](#process-data) \n",
    "    - Handle missing values \n",
    "    - Select variables\n",
    "    - Combine variables\n",
    "    - Filter observations (rows)\n",
    "    - Sort observations (rows)\n",
    "    - Select variables (columns)\n",
    "    - Exercise\n",
    "    - Assign new variables (columns) @Aurora\n",
    "    - Custom lambda functions on assign @Aurora\n",
    "    - Exercise @Aurora\n",
    "- [Aggregate Data](#aggregate-data)\n",
    "    - Date columns\n",
    "    - Group by common values\n",
    "    - Aggregations: sum, mean, first, median, count\n",
    "    - Looping through large datasets\n",
    "    - Exercise\n",
    "- [Method piping](#todo-method-piping)\n",
    "    - Piping example @Aurora\n",
    "- [Combine Data Tables](#combine-data-tables)\n",
    "    - Append tables of similar data\n",
    "    - Exercise\n",
    "    - Join tables with common variables\n",
    "    - Exercise \n",
    "- [Sharing Insights](#self-study---sharing-insights) @Aurora\n",
    "    - Mess up data for presentation with pivot\n",
    "    - Save to CSV\n",
    "    - More visualizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\").info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add parameters to read data properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\", header=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\", header=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = pd.read_csv(\"../data/kap1.csv\", header=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.loc[\"Norge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\", header=4, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = pd.read_csv(\"../data/kap1.csv\", header=4, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.loc[\"Norge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.Budsjettiltak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.Lån og garantier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget[\"Lån og garantier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.loc[:, \"Lån og garantier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/kap1.csv\", header=4, index_col=0).rename(\n",
    "    columns={\"Budsjettiltak\": \"tiltak\", \"Lån og garantier\": \"lån\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = pd.read_csv(\n",
    "    \"../data/kap1.csv\", header=4, index_col=0\n",
    ").rename(columns={\"Budsjettiltak\": \"tiltak\", \"Lån og garantier\": \"lån\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read data from the file `r\"..\\data\\driftsinntekter.csv\"` with `pandas`. Which parameters do you need to specify? Use the [`pandas` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) to look up available parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/driftsinntekter.csv\", header=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Data\n",
    "\n",
    "### Observations and variables\n",
    "\n",
    "Hadley Wickham introduced the term **tidy data** (<https://tidyr.tidyverse.org/articles/tidy-data.html>). Data tidying is a way to **structure DataFrames to facilitate analysis**.\n",
    "\n",
    "A DataFrame is tidy if:\n",
    "\n",
    "- Each variable is a column\n",
    "- Each observation is a row\n",
    "- Each DataFrame contains one observational unit\n",
    "\n",
    "Note that tidy data principles are closely tied to normalization of relational databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv(\"../data/driftsinntekter.csv\", header=1).rename(\n",
    "    columns={\"Category\": \"category\"}\n",
    ")\n",
    "income"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the `income` data frame tidy?\n",
    "\n",
    "> No, _2019_, _2020_, and _2021_ are not variables. They are values of a _year_ variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt messy datasets to tidy them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.melt(id_vars=[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "income.melt(id_vars=[\"category\"], var_name=\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.melt(id_vars=[\"category\"], var_name=\"year\", value_name=\"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = (\n",
    "    pd.read_csv(\"../data/driftsinntekter.csv\", header=1)\n",
    "    .rename(columns={\"Category\": \"category\"})\n",
    "    .melt(id_vars=[\"category\"], var_name=\"year\", value_name=\"income\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget.plot.barh()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Tidy the following data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = pd.DataFrame(\n",
    "    {\n",
    "        \"hour\": [19, 20, 21, 22],\n",
    "        \"NRK1\": [\"Dagsrevyen\", \"Beat for beat\", \"Nytt på nytt\", \"Lindmo\"],\n",
    "        \"TV2\": [\"Kjære landsmenn\", \"Forræder\", \"21-nyhetene\", \"Farfar\"],\n",
    "        \"TVNorge\": [\n",
    "            \"The Big Bang Theory\",\n",
    "            \"Alltid beredt\",\n",
    "            \"Kongen befaler\",\n",
    "            \"Praktisk info\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "schedule.melt(id_vars=[\"hour\"], var_name=\"channel\", value_name=\"program\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\")\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\",na_values=\"-\")\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\").rename(columns={\"duration\": \"rental_time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select variables and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.start_station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.end_station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips[\"start_station_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[:, \"start_station_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[[0, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[[0, 4],\"start_station_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[[0, 4],[\"start_station_name\", \"end_station_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.iloc[4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.iloc[5:8, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[5, \"started_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.loc[5, trips.columns[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.start_station_name + trips.end_station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.assign(combined_id=trips.start_station_id + trips.end_station_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.query(\"duration > 20000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.query(\"duration < 62\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.query(\"end_station_id >= start_station_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_budget = budget[budget[\"tiltak\"] > budget[\"lån\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_countries = [\"India\", \"Russland\", \"Korea\", \"Kina\", \"Japan\"]\n",
    "asian_budgets = budget[budget.index.isin(asian_countries)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.sort_values(by=\"duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.sort_values(by=[\"duration\", \"start_station_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "TODO: Something something bysykkel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - Assign new columns\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - Custom lambda functions on assign"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/09.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/09.csv\", parse_dates=[\"started_at\", \"ended_at\"])\n",
    "trips.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by common values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"num_trips\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"num_trips\"})\n",
    "    .sort_values(by=\"num_trips\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trips.groupby(\"end_station_name\")\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"num_trips\"})\n",
    "    .sort_values(by=\"num_trips\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips = (\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"num_trips\"})\n",
    "    .sort_values(by=\"num_trips\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations: sum, mean, median, first, count, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").agg(median_duration=(\"duration\", \"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sidenote, we could do the size example as follows\n",
    "trips.groupby(\"start_station_name\").agg(\n",
    "    num_trips=(\"start_station_name\", \"size\")\n",
    ").reset_index().sort_values(by=\"num_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby(\"start_station_name\").agg(\n",
    "    median_duration=(\"duration\", \"median\"),\n",
    "    description=(\"start_station_description\", \"first\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(column):\n",
    "    return column.mode().iloc[0]\n",
    "\n",
    "\n",
    "trips.groupby(\"start_station_name\").agg(\n",
    "    median_duration=(\"duration\", \"median\"),\n",
    "    description=(\"start_station_description\", \"first\"),\n",
    "    common_end_station=(\"end_station_name\", most_common),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby([\"start_station_name\", \"end_station_name\"]).agg(\n",
    "    median_duration=(\"duration\", \"median\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby([\"start_station_name\", \"end_station_name\"]).agg(\n",
    "    median_duration=(\"duration\", \"median\"),\n",
    "    start_station_description=(\"start_station_description\", \"first\"),\n",
    "    end_station_description=(\"end_station_description\", \"first\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.groupby([\"start_station_name\", \"end_station_name\"]).agg(\n",
    "    median_duration=(\"duration\", \"median\"),\n",
    "    start_station_description=(\"start_station_description\", \"first\"),\n",
    "    end_station_description=(\"end_station_description\", \"first\"),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in trips.iterrows():\n",
    "    trips.at[index, 'end_station_coordinates'] = str(row['end_station_latitude']) + ', ' + str(row['end_station_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['end_station_coordinates'] = trips['end_station_latitude'].astype(str) + ', ' + trips['end_station_longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trips)):\n",
    "    trips.at[i, 'trip_duration_minutes'] = (trips.at[i, 'ended_at'] - trips.at[i, 'started_at']).total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['trip_duration_minutes'] = (trips['ended_at'] - trips['started_at']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trips)):\n",
    "    trips.at[i, 'long_trip'] = trips.at[i, 'trip_duration_minutes'] > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['long_trip'] = [trip.trip_duration_minutes > 30 for trip in trips.itertuples()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "You have a dataset for the month of September (09.csv), containing information about bike trips. Your task is to aggregate the data and find the total number of long trips (where the duration is greater than 30 minutes) for each end station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_sep = pd.read_csv(\"../data/09.csv\", parse_dates=[\"started_at\", \"ended_at\"])\n",
    "\n",
    "trips_sep['long_trip'] = trips_sep['duration'] > 30\n",
    "long_trip_counts = trips_sep.groupby('end_station_name')['long_trip'].sum().reset_index()\n",
    "long_trip_counts.columns = ['end_station_name', 'total_long_trips']\n",
    "\n",
    "print(long_trip_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Method piping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data Tables\n",
    "\n",
    "We have two files with the same kinds of data: `08.csv` with data for August and `09.csv` with data for September. How can we combine them into one DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_aug = pd.read_csv(\"../data/08.csv\", parse_dates=[\"started_at\", \"ended_at\"])\n",
    "trips_sep = pd.read_csv(\"../data/09.csv\", parse_dates=[\"started_at\", \"ended_at\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append tables with similar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([trips_aug, trips_sep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([trips_aug, trips_sep]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([trips_aug, trips_sep]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filnavn in [\"../data/08.csv\", \"../data/09.csv\"]:\n",
    "    print(filnavn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filnavn in [\"../data/08.csv\", \"../data/09.csv\"]:\n",
    "    print(filnavn)\n",
    "    trips = pd.read_csv(filnavn, parse_dates=[\"started_at\", \"ended_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.started_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "for filnavn in [\"../data/08.csv\", \"../data/09.csv\"]:\n",
    "    print(filnavn)\n",
    "    months.append(pd.read_csv(filnavn, parse_dates=[\"started_at\", \"ended_at\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "for filnavn in [\"../data/08.csv\", \"../data/09.csv\"]:\n",
    "    print(filnavn)\n",
    "    months.append(pd.read_csv(filnavn, parse_dates=[\"started_at\", \"ended_at\"]))\n",
    "trips = pd.concat(months).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "pathlib.Path.cwd().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pathlib.Path.cwd().parent / \"data\").glob(\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((pathlib.Path.cwd().parent / \"data\").glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "for filnavn in [\"../data/08.csv\", \"../data/09.csv\"]:\n",
    "    print(filnavn)\n",
    "    months.append(pd.read_csv(filnavn, parse_dates=[\"started_at\", \"ended_at\"]))\n",
    "trips = pd.concat(months).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "You have two datasets, one for August (08.csv) and another for September (09.csv). Each dataset contains information about bike trips. Your task is to combine these two datasets and find out the total number of bike trips for each station in these two months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasit\n",
    "\n",
    "# Read the data\n",
    "trips_aug = pd.read_csv(\"../data/08.csv\", parse_dates=[\"started_at\", \"ended_at\"])\n",
    "trips_sep = pd.read_csv(\"../data/09.csv\", parse_dates=[\"started_at\", \"ended_at\"])\n",
    "\n",
    "# Combine the datasets\n",
    "trips = pd.concat([trips_aug, trips_sep]).reset_index(drop=True)\n",
    "\n",
    "# Count the number of trips for each station\n",
    "station_counts = trips['start_station_name'].value_counts().reset_index()\n",
    "station_counts.columns = ['start_station_name', 'trip_count']\n",
    "\n",
    "print(station_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join tables with common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips = (\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .size()\n",
    "    .reset_index(name=\"num_trips\")\n",
    "    .sort_values(by=\"num_trips\")\n",
    ")\n",
    "num_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_lengths = (\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .agg(median_duration=(\"duration\", \"median\"))\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"median_duration\")\n",
    ")\n",
    "trip_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(num_trips, trip_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips_from = (\n",
    "    trips.groupby(\"start_station_name\")\n",
    "    .agg(num_trips=(\"start_station_name\", \"size\"))\n",
    "    .sort_values(by=\"num_trips\")\n",
    "    .reset_index()\n",
    ")\n",
    "num_trips_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips_to = (\n",
    "    trips.groupby(\"end_station_name\")\n",
    "    .agg(num_trips=(\"end_station_name\", \"size\"))\n",
    "    .sort_values(by=\"num_trips\")\n",
    "    .reset_index()\n",
    ")\n",
    "num_trips_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(num_trips_from, num_trips_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    num_trips_from,\n",
    "    num_trips_to,\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_from = num_trips_from.nlargest(10, \"num_trips\")\n",
    "popular_to = num_trips_to.nlargest(10, \"num_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    popular_from, popular_to, left_on=\"start_station_name\", right_on=\"end_station_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    popular_from,\n",
    "    popular_to,\n",
    "    how=\"inner\",\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    popular_from,\n",
    "    popular_to,\n",
    "    how=\"left\",\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    popular_from,\n",
    "    popular_to,\n",
    "    how=\"right\",\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    popular_from,\n",
    "    popular_to,\n",
    "    how=\"outer\",\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Merge the trips DataFrame with the stations DataFrame to add the address and number of bike docks for each start station to the trips DataFrame. We want to merge on the start_station_id in the trips DataFrame and the station_id in the stations DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.DataFrame({\n",
    "    'station_id': [564, 421, 621, 447, 430, 558, 424, 428],\n",
    "    'station_name': ['Oscars gate', 'Alexander Kiellands Plass', 'Torshovdalen øst', 'Kværnerbyen', 'Spikersuppa Vest', 'Dokkveien', 'Birkelunden', 'Olav Kyrres plass'],\n",
    "    'address': ['Oscars gate 1', 'Alexander Kiellands Plass 2', 'Torshovdalen øst 3', 'Kværnerbyen 4', 'Spikersuppa Vest 5', 'Dokkveien 6', 'Birkelunden 7', 'Olav Kyrres plass 8'],\n",
    "    'num_docks': [10, 15, 12, 14, 16, 14, 15, 12]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasit\n",
    "\n",
    "# Rename the columns in stations to indicate they are about the start station\n",
    "stations.columns = ['start_station_id', 'start_station_name', 'start_station_address', 'start_station_num_docks']\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_trips = pd.merge(trips, stations, on=['start_station_id', 'start_station_name'], how='left')\n",
    "\n",
    "print(merged_trips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "What is the 10 most popular destionations from Alexander Kiellands Plass? Sorted from most rides to frewest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasit\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_trips = trips[trips['start_station_name'] == 'Alexander Kiellands Plass']\n",
    "\n",
    "# Group by end_station_name and count, sort in descending order, take top 10\n",
    "top_10_end_stations = filtered_trips.groupby('end_station_name').size().sort_values(ascending=False).head(10).reset_index(name='count')\n",
    "\n",
    "print(top_10_end_stations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self study - Sharing Insights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mess up data for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to = (\n",
    "    trips.groupby([\"start_station_name\", \"end_station_name\"])\n",
    "    .agg(num_trips=(\"start_station_name\", \"size\"))\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"num_trips\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to.query(\n",
    "    \"start_station_name.isin(@popular_from.start_station_name) and end_station_name.isin(@popular_to.end_station_name)\"\n",
    ").pivot_table(\n",
    "    index=\"start_station_name\", columns=\"end_station_name\", values=\"num_trips\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to.to_csv(\"from_to.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips_to = (\n",
    "    trips.groupby(\"end_station_name\")\n",
    "    .agg(num_trips=(\"end_station_name\", \"size\"), lat=(\"end_station_latitude\", \"first\"), lon=(\"end_station_longitude\", \"first\"))\n",
    "    .sort_values(by=\"num_trips\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.merge(\n",
    "    num_trips_from,\n",
    "    num_trips_to,\n",
    "    left_on=\"start_station_name\",\n",
    "    right_on=\"end_station_name\",\n",
    "    suffixes=(\"_from\", \"_to\")\n",
    ").assign(from_over_to=lambda df: np.log(df.num_trips_from/df.num_trips_to)).plot.scatter(x=\"lon\", y=\"lat\", c=\"from_over_to\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.852,
   "position": {
    "height": "40px",
    "left": "1170px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "4636e1197519ade21a40484ae7db3eb2c79ccbdfbf1a0e66ae49162eef07d099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
